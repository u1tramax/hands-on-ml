{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da027946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_softmaxreg(X: np.ndarray, y: np.ndarray, learning_rate: float, iterations: int) -> tuple[list[float], ...]:\n",
    "\t# Your code here\n",
    "    def _softmax(z):\n",
    "        return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n",
    "    \n",
    "    def _to_one_hot(y):\n",
    "        y_hot = np.zeros( (len(y), len(np.unique(y)) ) )\n",
    "        for i in range(len(y)):\n",
    "            y_hot[i, y[i]] = 1\n",
    "        return y_hot\n",
    "    \n",
    "    def cross_entropy(y_pred, y_true):\n",
    "        true_labels_idx = np.argmax(y_true, axis=1)\n",
    "        return -np.sum(np.log(y_pred)[list(range(len(y_pred))),true_labels_idx])\n",
    "\n",
    "    m, n = X.shape\n",
    "    X = np.c_[np.ones(m), X]\n",
    "    n += 1\n",
    "    theta = np.zeros( (n, len(np.unique(y)) ) )\n",
    "    y_hot = _to_one_hot(y)\n",
    "    loss = []\n",
    "    for _ in range(iterations):\n",
    "        y_pred = _softmax(X @ theta)\n",
    "        gradients = X.T @ (y_pred - y_hot)\n",
    "        theta -= learning_rate * gradients\n",
    "        loss.append(np.round(cross_entropy(y_pred, y_hot), 4))\n",
    "    return np.round(theta.T, 4), loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08c79328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.0011,  0.0145, -0.0921],\n",
       "        [ 0.002 , -0.0598,  0.1263],\n",
       "        [-0.0009,  0.0453, -0.0342]]),\n",
       " [np.float64(3.2958),\n",
       "  np.float64(3.2611),\n",
       "  np.float64(3.2272),\n",
       "  np.float64(3.1941),\n",
       "  np.float64(3.1618),\n",
       "  np.float64(3.1302),\n",
       "  np.float64(3.0993),\n",
       "  np.float64(3.0692),\n",
       "  np.float64(3.0398),\n",
       "  np.float64(3.011)])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_softmaxreg(\n",
    "    np.array([[0.5, -1.2], [-0.3, 1.1], [0.8, -0.6]]), \n",
    "    np.array([0, 1, 2]), \n",
    "    0.01,\n",
    "    10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878232a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def analyze_ab_test(control_outcomes: list, treatment_outcomes: list, confidence_level: float = 0.95, min_detectable_effect: float = 0.02) -> dict:\n",
    "\n",
    "    # Checking if any group is empty or not\n",
    "    if not control_outcomes or not treatment_outcomes:\n",
    "        return {}\n",
    "\n",
    "    # Changing to numpy arrays for broadcast and calculating sample sizes\n",
    "    control_outcomes = np.array(control_outcomes)\n",
    "    treatment_outcomes = np.array(treatment_outcomes)\n",
    "    n1 = control_outcomes.size\n",
    "    n2 = treatment_outcomes.size\n",
    "\n",
    "    # Calculating statistics for further calculations\n",
    "    control_count = (control_outcomes == 1).sum()\n",
    "    treatment_count = (treatment_outcomes == 1).sum()\n",
    "\n",
    "    control_rate = control_count / n1\n",
    "    treatment_rate = treatment_count / n2\n",
    "\n",
    "    absolute_lift = treatment_rate - control_rate\n",
    "    relative_lift = absolute_lift / control_rate\n",
    "\n",
    "    # Calculating z-statistic and p-value\n",
    "    p = (control_count + treatment_count) / (n1 + n2)\n",
    "    z_statistic = (treatment_rate - control_rate) / (np.sqrt(p * (1 - p) * (1/n1 + 1/n2)))\n",
    "    p_value = stats.norm.sf(abs(z_statistic)) * 2\n",
    "\n",
    "    # Confidence interval\n",
    "    z_alpha = stats.norm.ppf(1 - (1 - confidence_level)/2)\n",
    "    se = np.sqrt(control_rate * (1 - control_rate) / n1 + treatment_rate * (1 - treatment_rate) / n2)\n",
    "    confidence_interval = (treatment_rate - control_rate - se * z_alpha, treatment_rate - control_rate + se * z_alpha)\n",
    "\n",
    "    # Calculating significance\n",
    "    statistical_significance = p_value < (1 - confidence_level)\n",
    "    practical_significance = abs(absolute_lift) >= min_detectable_effect\n",
    "\n",
    "    # Sample size and recommendation\n",
    "    z_beta = stats.norm.ppf(0.8)\n",
    "    required_sample_size = (2 * (z_alpha + z_beta) ** 2  * p * (1 - p)) / min_detectable_effect\n",
    "\n",
    "    if statistical_significance and practical_significance and absolute_lift > 0:\n",
    "        recommendation = 'launch_treatment'\n",
    "    elif statistical_significance and (not practical_significance or absolute_lift < 0):\n",
    "        recommendation = 'keep_control'\n",
    "    else:\n",
    "        recommendation = 'continue_testing'\n",
    "\n",
    "    return {\n",
    "        'control_rate': control_rate,\n",
    "        'treatment_rate': treatment_rate,\n",
    "        'absolute_lift': round(absolute_lift, 2),\n",
    "        'relative_lift': relative_lift,\n",
    "        'z_statistic': round(z_statistic, 4),\n",
    "        'p_value': p_value,\n",
    "        'confidence_interval': confidence_interval,\n",
    "        'statistically_significant': statistical_significance,\n",
    "        'practically_significant': practical_significance,\n",
    "        'required_sample_size': required_sample_size,\n",
    "        'recommendation': recommendation\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d00eb78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'control_rate': np.float64(0.5),\n",
       " 'treatment_rate': np.float64(0.6),\n",
       " 'absolute_lift': np.float64(0.09999999999999998),\n",
       " 'relative_lift': np.float64(0.55),\n",
       " 'z-statistic': np.float64(3.17820863081864),\n",
       " 'p-value': np.float64(0.0014818807747203912),\n",
       " 'confidence-interval': (np.float64(0.16135657784036067),\n",
       "  np.float64(0.03864342215963927))}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_outcomes = [1,1,1,0,0,0,1,0,1,0]*50\n",
    "treatment_outcomes = [1,1,1,1,0,0,1,0,1,0]*50\n",
    "confidence_level = 0.95\n",
    "min_detectable_effect = 0.02\n",
    "analyze_ab_test(control_outcomes, treatment_outcomes, confidence_level, min_detectable_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e23d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
