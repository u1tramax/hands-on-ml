{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d48d3945",
   "metadata": {},
   "source": [
    "# **Линейная регрессия**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a87c4cd",
   "metadata": {},
   "source": [
    "## **Подготовка для работы в Google Colab или Kaggle**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ec922",
   "metadata": {},
   "source": [
    "#### Код для подключения Google Drive в Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31e8aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae28eb",
   "metadata": {},
   "source": [
    "#### Код для получения пути к файлам в Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0445aaad",
   "metadata": {},
   "source": [
    "#### Код для установки библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9223df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scipy==1.16.3 numpy==2.0.2 pandas==2.2.2 scikit-learn==1.6.1 statsmodels==0.14.6 matplotlib==3.10.0 seaborn==0.13.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bcb060",
   "metadata": {},
   "source": [
    "## **Важная информация**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8946d9b8",
   "metadata": {},
   "source": [
    "**Для правильного воспроизведения результатов** решения задач:\n",
    "\n",
    "* Рекомендуется придерживаться имеющего в заданиях кода в исходной последовательности. Для этого при решении задач **восстановите недостающие фрагменты кода, которые отмечены символом** `...` (Ellipsis).\n",
    "\n",
    "* Если класс, функция или метод предусматривает параметр random_state, всегда указывайте **random_state=RANDOM_STATE**.\n",
    "\n",
    "* Для всех параметров (кроме random_state) класса, функции или метода **используйте значения по умолчанию, если иное не указано в задании**.\n",
    "\n",
    "**Если скорость обучения слишком низкая**, рекомендуется следующее:\n",
    "\n",
    "* В модели или/и GridSearchCV поменяйте значение параметра n_jobs, который отвечает за параллелизм вычислений.\n",
    "\n",
    "* Воспользуйтесь вычислительными ресурсами Google Colab или Kaggle.\n",
    "\n",
    "***Использовать GPU не рекомендуется, поскольку результаты обучения некоторых моделей могут отличаться на CPU и GPU.***\n",
    "\n",
    "После выполнения каждого задания **ответьте на вопросы в тесте.**\n",
    "\n",
    "**ВНИМАНИЕ:** **После каждого нового запуска ноутбука** перед тем, как приступить к выполнению заданий, проверьте настройку виртуального окружения, выполнив код в ячейке ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d090218e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Компонент       | Требуется    | Установлено  | Соответствие\n",
      "--------------------------------------------------------------\n",
      "python          | 3.12.x       | 3.13.5       | x (требуется 3.12.x)\n",
      "scipy           | 1.16.3       | 1.15.3       | x (требуется 1.16.3)\n",
      "numpy           | 2.0.2        | 2.1.3        | x (требуется 2.0.2)\n",
      "pandas          | 2.2.2        | 2.2.3        | x (требуется 2.2.2)\n",
      "scikit-learn    | 1.6.1        | 1.6.1        | ✓           \n",
      "statsmodels     | 0.14.6       | 0.14.4       | x (требуется 0.14.6)\n",
      "matplotlib      | 3.10.0       | 3.10.0       | ✓           \n",
      "seaborn         | 0.13.2       | 0.13.2       | ✓           \n",
      "\n",
      "Результат проверки:  x\n",
      "ВНИМАНИЕ: Версии некоторых компонентов не соответствуют требованиям!\n",
      "Для решения проблемы обратитесь к инструкции по настройке виртуального окружения\n"
     ]
    }
   ],
   "source": [
    "# Код для проверки настройки виртуального окружения\n",
    "\n",
    "import sys\n",
    "from importlib.metadata import version\n",
    "\n",
    "required = {\n",
    "    'python': '3.12.x',\n",
    "    'scipy': '1.16.3',\n",
    "    'numpy': '2.0.2',\n",
    "    'pandas': '2.2.2',\n",
    "    'scikit-learn': '1.6.1',\n",
    "    'statsmodels': '0.14.6',\n",
    "    'matplotlib': '3.10.0',\n",
    "    'seaborn': '0.13.2'\n",
    "}\n",
    "\n",
    "print(f'{\"Компонент\":<15} | {\"Требуется\":<12} | {\"Установлено\":<12} | {\"Соответствие\"}')\n",
    "print('-' * 62)\n",
    "\n",
    "environment_ok = True\n",
    "for lib, req_ver in required.items():\n",
    "    try:\n",
    "        if lib=='python':\n",
    "            inst_ver = sys.version.split()[0]\n",
    "            status = '✓' if sys.version_info.major == 3 and sys.version_info.minor == 12 else f'x (требуется {req_ver})'\n",
    "        else:\n",
    "            inst_ver = version(lib)\n",
    "            if inst_ver == req_ver:\n",
    "                status = '✓'\n",
    "            else:\n",
    "                environment_ok = False\n",
    "                status = f'x (требуется {req_ver})'\n",
    "    except:\n",
    "        environment_ok = False\n",
    "        inst_ver = '-'\n",
    "        status = 'x (не установлена)'\n",
    "    print(f'{lib:<15} | {req_ver:<12} | {inst_ver:<12} | {status:<12}')\n",
    "\n",
    "print('\\nРезультат проверки: ', \n",
    "      '✓\\nВсе версии соответствуют требованиям' \n",
    "      if environment_ok else \n",
    "      'x\\nВНИМАНИЕ: Версии некоторых компонентов не соответствуют требованиям!\\n'\n",
    "      'Для решения проблемы обратитесь к инструкции по настройке виртуального окружения')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ade49f",
   "metadata": {},
   "source": [
    "## **Импорт библиотек и вспомогательные функции**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e321eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08b97525-8a79-4b74-b6a7-4024348905c1",
   "metadata": {
    "executionInfo": {
     "elapsed": 11892,
     "status": "ok",
     "timestamp": 1741916272286,
     "user": {
      "displayName": "Ivan Komarov",
      "userId": "15572440089742707458"
     },
     "user_tz": -420
    },
    "id": "08b97525-8a79-4b74-b6a7-4024348905c1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn import datasets\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.diagnostic import het_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a90bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a39fe3-a2f3-4041-8e8e-9d8f2fcaa132",
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1741916272329,
     "user": {
      "displayName": "Ivan Komarov",
      "userId": "15572440089742707458"
     },
     "user_tz": -420
    },
    "id": "60a39fe3-a2f3-4041-8e8e-9d8f2fcaa132"
   },
   "outputs": [],
   "source": [
    "def metrics_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Выводит отчёт с основными метриками качества регрессии.\n",
    "    Округляет до 4-х знаков после запятой и выводит значения R2 (коэффициент детерминации), RMSE (среднеквадратичная ошибка) и MAPE (средняя абсолютная процентная ошибка) для оценки качества предсказаний.\n",
    "\n",
    "    Аргументы:\n",
    "        y_true (numpy.ndarray): Истинные значения целевой переменной.\n",
    "        y_pred (numpy.ndarray): Предсказанные значения целевой переменной.\n",
    "    \"\"\"\n",
    "    print(f'R2 score: {r2_score(y_true, y_pred):.4f}')\n",
    "    print(f'RMSE: {mean_squared_error(y_true, y_pred)**0.5:.4f}')\n",
    "    print(f'MAPE: {mean_absolute_percentage_error(y_true, y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab798146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_adj_score(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    Рассчитывает скорректированный коэффициент детерминации (Adj. R²).\n",
    "    \n",
    "    Аргументы:\n",
    "        y_true (numpy.ndarray): Истинные значения целевой переменной.\n",
    "        y_pred (numpy.ndarray): Предсказанные значения целевой переменной.\n",
    "        k (int): Количество факторов.\n",
    "\n",
    "    Возвращает:\n",
    "        float: Значение скорректированного коэффициента детерминации.\n",
    "    \"\"\"\n",
    "    return 1 - (1 - r2_score(y_true, y_pred)) * (len(y_true) - 1) / (len(y_true) - k - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29eb532",
   "metadata": {},
   "source": [
    "## **Практическая часть**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab0e90",
   "metadata": {},
   "source": [
    "### **Значимость коэффициентов линейной регрессии**\n",
    "\n",
    "Линейная регрессия позволяет проверять статистические гипотезы, связанные с влиянием независимых переменных (факторов) на зависимую переменную. В частности, гипотезу о значимости коэффициентов регрессии:\n",
    "\n",
    "* Нулевая гипотеза ($H_0$): Коэффициент при факторе $i$ равен нулю: $\\beta_i = 0$ (нет влияния).\n",
    "\n",
    "* Альтернативная гипотеза ($H_1$): $\\beta_i \\ne 0$ (фактор значимо влияет на зависимую переменную).\n",
    "\n",
    "* Метод проверки: t-тест для коэффициентов (если p-value < $\\alpha$ (обычно 0.05), отвергаем $H_0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192e2643",
   "metadata": {},
   "source": [
    "### **Коэффициент детерминации ($R^2$)**\n",
    "\n",
    "**Коэффициент детерминации** ($R^2$) — это статистическая мера, которая показывает, насколько хорошо модель линейной регрессии объясняет вариацию (дисперсию) зависимой переменной. $R^2$ вычисляется по формуле:\n",
    "\n",
    "$$R^2=1−​\\frac{SS_{res}}{​SS_{total}}$$\n",
    "\n",
    "где $SS_{res}$​ — сумма квадратов остатков (необъяснённая дисперсия), $SS_{total}$​ — общая сумма квадратов (общая дисперсия зависимой переменной).\n",
    "\n",
    "Чем ближе значение $R^2$ к 1, тем модель лучше объясняет изменения зависимой переменной ($0 \\le R^2 \\le 1$).\n",
    "\n",
    "Пример: если $R^2=0.75$, то это означает, что 75% изменений зависимой переменной объясняются моделью, а 25% — случайными факторами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a71e60-9ed2-479e-834c-0d93475bc5c6",
   "metadata": {
    "id": "71a71e60-9ed2-479e-834c-0d93475bc5c6",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ***Задание 1***\n",
    "\n",
    "Сгенерируйте две переменные:\n",
    "\n",
    "* `feature` (объясняющий фактор): значение некоторой характеристики товара.\n",
    "\n",
    "* `cost` (целевая/объясняемая переменная): стоимость товара.\n",
    "\n",
    "Обучите две модели линейной регрессии на `feature` (предобработка данных не требуется):\n",
    "\n",
    "* `sk_reg` — модель LinearRegression из библиотеки sklearn (scikit-learn).\n",
    "\n",
    "* `sm_reg` — модель OLS из библиотеки statsmodels.\n",
    "\n",
    "Сравните значения коэффициентов обученных моделей `sk_reg` и `sm_reg`, и для модели `sm_reg` проверьте статистическую значимость коэффициентов с помощью метода [summary](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLSResults.summary.html).\n",
    "\n",
    "Рассчитайте $R^2$ для обеих моделей.\n",
    "\n",
    "**ВНИМАНИЕ:** Перед обучением линейной регрессии в statsmodels (`sm_reg`) необходимо добавить константу к `feature` с помощью метода [add_constant](https://tedboy.github.io/statsmodels_doc/generated/statsmodels.api.add_constant.html).\n",
    "\n",
    "*Библиотека statsmodels больше ориентирована на статистический анализ и проверку гипотез, тогда как scikit-learn ориентирован на выполнение множества задач в рамках машинного обучения, включая предобработку данных, обучение широкого спектра не классических моделей (в отличие от statsmodels), пайплайны (конвейеры) и многое другое.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3571044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сгенерируйте переменные feature и cost\n",
    "# Переменная rng позволит зафиксировать RANDOM_STATE при генерации случайных чисел в numpy\n",
    "\n",
    "rng = np.random.RandomState(RANDOM_STATE)\n",
    "\n",
    "feature = rng.uniform(0, 100, 1000)\n",
    "cost = feature + rng.normal(3000, 500, 1000)\n",
    "\n",
    "feature = feature.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c11a41-8694-40a6-9c13-f5184fb92eaf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 740,
     "status": "ok",
     "timestamp": 1741916331806,
     "user": {
      "displayName": "Ivan Komarov",
      "userId": "15572440089742707458"
     },
     "user_tz": -420
    },
    "id": "02c11a41-8694-40a6-9c13-f5184fb92eaf",
    "outputId": "fde1c839-762a-496d-d14f-8d57a9cc58c2"
   },
   "outputs": [],
   "source": [
    "# Постройте точечную диаграмму (scatter plot) cost ~ feature\n",
    "\n",
    "plt.scatter(\n",
    "    x=...,\n",
    "    y=...\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e4e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите модель sk_reg на всем наборе данных и рассмотрите коэффициенты обученной модели\n",
    "\n",
    "sk_reg = LinearRegression().fit(...)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec31195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте метрики качества модели sk_reg\n",
    "\n",
    "metrics_report(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7fdab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите модель sm_reg на всем наборе данных и рассмотрите вывод метода summary\n",
    "# Перед обучением sm_reg необходимо добавить константу к feature с помощью метода add_constant\n",
    "\n",
    "feature_const = ...\n",
    "sm_reg = OLS(...).fit()\n",
    "print(sm_reg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0dbfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте метрики качества модели sm_reg\n",
    "\n",
    "metrics_report(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba1ddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте точечную диаграмму cost ~ feature и нанесите на нее предсказания одной из моделей\n",
    "\n",
    "plt.scatter(\n",
    "    x=...,\n",
    "    y=...\n",
    ")\n",
    "plt.plot(feature, ..., color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8539c856",
   "metadata": {},
   "source": [
    "### **Экзогенность факторов линейной регрессии**\n",
    "\n",
    "Одно из ключевых предположений линейной регрессии — экзогенность, которая подразумевает, что объясняющие переменные (факторы) не коррелируют с ошибками: \n",
    "\n",
    "$$\\mathbb{E}[\\varepsilon_i|X]=0 \\; \\forall i$$\n",
    "\n",
    "где $\\mathbb{E}$ — условное математическое ожидание, $\\varepsilon_i$ — ошибка для i-го наблюдения, $X$ — матрица всех объясняющих факторов.\n",
    "\n",
    "**Если предположение об экзогенности нарушается, то оценки регрессии могут стать смещенными и несостоятельными.**\n",
    "\n",
    "**Примеры нарушения экзогенности:**\n",
    "\n",
    "* Целевая переменная влияет на фактор. Например, в ситуации, когда моделируется влияние образования на доход, обратная причинность заключается в том, что более высокий доход также позволяет инвестировать в дополнительное образование.\n",
    "\n",
    "* Фактор и целевая переменная определяются одновременно. Например, в модели спроса и предложения, цена и количество определяются одновременно.\n",
    "\n",
    "* **Смещение пропущенной переменной (omitted-variable bias)**: существует скрытый фактор $t$, который влияет как на фактор $x$, так и на целевую переменную $f$, но не включен в модель.\n",
    "\n",
    "Схема смещения пропущенной переменной:\n",
    "\n",
    "\n",
    "```\n",
    "                         +-----------------------+\n",
    "            +----------->| Фактор x              |\n",
    "            |            +-----------+-----------+\n",
    "            |                        |            \n",
    "+-----------+-----------+            |            \n",
    "| Скрытый фактор t      |            |            \n",
    "+-----------+-----------+            |            \n",
    "            |                        V            \n",
    "            |            +-----------+-----------+\n",
    "            +----------->| Целевая переменная f  |\n",
    "                         +-----------------------+\n",
    "```\n",
    "\n",
    "В ситуации смещения пропущенной переменной наблюдаемая корреляция между $x$ и $f$ может быть частично или полностью обусловлена влиянием $t$, а не прямой причинно-следственной связью между $x$ и $f$. Если $t$ не включен в модель, его влияние будет поглощено членом ошибки, что приведет к корреляции между фактором $x$ и ошибкой $\\varepsilon$. Это нарушает предположение строгой экзогенности и делает оценки регрессии смещенными и несостоятельными."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d766583",
   "metadata": {},
   "source": [
    "### **Задание 2**\n",
    "\n",
    "Сгенерируйте три переменные для моделирования ситуации смещения пропущенной переменной:\n",
    "\n",
    "* Скрытый ненаблюдаемый фактор `t`.\n",
    "\n",
    "* Фактор `x`, на который влияет `t`.\n",
    "\n",
    "* Целевая переменная `f`, на которую влияют факторы `t` и `x`.\n",
    "\n",
    "Обучите две модели линейной регрессии statsmodels (OLS):\n",
    "\n",
    "* `reg_biased` — f ~ x (модель предсказывает `f` по значениям `x`).\n",
    "\n",
    "* `reg_unbiased` — f ~ x + t (модель предсказывает `f` по значениям `x` и `t`).\n",
    "\n",
    "Выведите summary для `reg_biased` и `reg_unbiased`, сравните коэффициенты при факторах в моделях `reg_biased` и `reg_unbiased` с истинными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e725ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сгенерируйте скрытый фактор t\n",
    "# Сгенерируйте фактор x, на который влияет t\n",
    "# Сгенерируйте целевую переменную f, на которую влияют факторы t и x\n",
    "# Истинные коэффициенты при факторах:\n",
    "#   x: 2\n",
    "#   t: -4\n",
    "# Переменная rng позволит зафиксировать RANDOM_STATE при генерации случайных чисел в numpy\n",
    "\n",
    "rng = np.random.RandomState(RANDOM_STATE)\n",
    "\n",
    "t = rng.normal(0, 1, 1000)\n",
    "x = 0.5 * t + rng.normal(0, 0.5, 1000)\n",
    "f = 2 * x - 4 * t + rng.normal(0, 1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c5aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите модель f ~ x и выведите summary\n",
    "# Перед обучением reg_biased необходимо добавить константу с помощью метода add_constant\n",
    "\n",
    "X_biased = ...\n",
    "reg_biased = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите модель f ~ x + t и выведите summary\n",
    "# Перед обучением reg_unbiased необходимо добавить константу с помощью метода add_constant\n",
    "\n",
    "X_unbiased = ...\n",
    "reg_unbiased = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ef624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравните коэффициенты при факторах в моделях reg_biased и reg_unbiased с истинными\n",
    "\n",
    "print('Истинный коэффициент при x: 2')\n",
    "print('Истинный коэффициент при t: - 4')\n",
    "\n",
    "print(f'Смещенный коэффициент при x (f ~ x): {...}')\n",
    "\n",
    "print(f'Несмещенный коэффициент при x (f ~ x + t): {...}')\n",
    "print(f'Несмещенный коэффициент при t (f ~ x + t) {...}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afa58b0",
   "metadata": {},
   "source": [
    "### **Предобработка данных**\n",
    "\n",
    "**Предобработка данных** — это важнейший аспект машинного обучения, который напрямую влияет на качество, точность и производительность моделей ML. Данные в сыром виде часто бывают неполными или плохо структурированными, и без их предварительной подготовки построение эффективных моделей практически невозможно.\n",
    "\n",
    "**Основные этапы предобработки данных:**\n",
    "\n",
    "1. **Сбор и интеграция данных.** Загрузка данных из одного или нескольких источников и объединение их в один датасет (или несколько датасетов).\n",
    "\n",
    "2. **Первичный анализ данных.** Подсчет статистических характеристик датасета, построение графиков и оценка корреляционных зависимостей между переменными.\n",
    "\n",
    "3. **Очистка данных.** Удаление дубликатов и исправление явных ошибок (опечатки, отрицательный возраст).\n",
    "\n",
    "4. **Обработка пропусков.** \n",
    "\n",
    "* Удаление строк с пропусками.\n",
    "\n",
    "* Удаление столбцов с пропусками.\n",
    "\n",
    "* Заполнение описательными характеристиками (средним/модой/медианой).\n",
    "\n",
    "* Заполнение прогнозом (KNN, Regression, MICE).\n",
    "\n",
    "5. **Обработка категориальных признаков.**\n",
    "\n",
    "* One-Hot Encoding.\n",
    "\n",
    "* Ordinal/Label Encoding.\n",
    "\n",
    "6. **Разделение данных.** Разделение данных на обучающую, валидационную и тестовую выборки.\n",
    "\n",
    "7. **Масштабирование числовых (количественных) признаков.**\n",
    "\n",
    "* StandardScaler.\n",
    "\n",
    "* MinMaxScaler.\n",
    "\n",
    "*Это лишь основные этапы предобработки данных. На практике количество существующих методов обработки данных намного больше, а структура и порядок этапов **зависит от решаемой задачи***.\n",
    "\n",
    "**Необходимым условием правильного выполнения последующих заданий является правильная предобработка данных.**\n",
    "\n",
    "Процедура предобработки указывается в заданиях курса и, как правило, включает в себя считывание данных, выделение целевой переменной, обработку категориальных признаков с помощью One-Hot кодирования, разделение данных на обучающую (train) и тестовую (test) выборки, а также масштабирование числовых признаков с помощью стандартизации (Standard Scaler)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4404ed90",
   "metadata": {},
   "source": [
    "### **Датасет *Housing Prices Dataset***\n",
    "\n",
    "**Для решения заданий 3 — 9 рассмотрим датасет [Housing Prices Dataset](https://www.kaggle.com/datasets/yasserh/housing-prices-dataset).**\n",
    "\n",
    "Набор данных предназначен для решения задачи регрессии — прогнозирования цены дома на основе его характеристик.\n",
    "\n",
    "Целевая переменная — price (цена дома).\n",
    "\n",
    "Датасет содержит признаки:\n",
    "\n",
    "* Площадь (area).\n",
    "\n",
    "* Количество комнат (bedrooms, bathrooms).\n",
    "\n",
    "* Количество этажей (stories).\n",
    "\n",
    "* Количество парковочных мест (parking).\n",
    "\n",
    "* Близость к главной дороге, категориальный (mainroad).\n",
    "\n",
    "* Уровень меблировки, категориальный (furnishingstatus).\n",
    "\n",
    "* Наличие гостевой комнаты и подвала, бинарные (guestroom, basement).\n",
    "\n",
    "* Наличие водонагревателя и кондиционера, бинарные (hotwaterheating, airconditioning).\n",
    "\n",
    "* Находится ли дом в предпочтительном районе (prefarea)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6708a1a6",
   "metadata": {},
   "source": [
    "### ***Задание 3***\n",
    "\n",
    "Выполните предобработку данных:\n",
    "\n",
    "1. **read_csv**: считайте набор данных стоимости жилья и выделите объясняемый фактор в отдельную переменную.\n",
    "\n",
    "2. **OneHotEncoder:** закодируйте категориальные переменные значениями 0 и 1.\n",
    "\n",
    "3. **train_test_split:** разделите датасет на обучающую (60%) и тестовую (40%).\n",
    "\n",
    "4. **StandardScaler:** масштабируйте количественные переменные.\n",
    "\n",
    "Используя метод describe, рассмотрите статистические характеристики исходного датасета и подготовленных выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae2b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считайте набор данных\n",
    "\n",
    "df_housing = pd.read_csv('house_prices.csv')\n",
    "df_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4269c0b0",
   "metadata": {},
   "source": [
    "#### **Как определить тип признака с помощью метода [info](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html)**\n",
    "\n",
    "Метод info (pandas) выводит тип данных (dtype) каждого столбца, но не классифицирует их явно на количественные и категориальные. Однако по dtype можно сделать предположение:\n",
    "\n",
    "* int, float — как правило, количественные, но могут быть и категориальными (например, бинарный признак 0/1 или порядковый код категории).\n",
    "\n",
    "* object, string, bool, category — как правило, категориальные.\n",
    "\n",
    "**ВНИМАНИЕ:** В используемом датасете int64 — количественные, object —категориальные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f00d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используя метод info, определите типы признаков\n",
    "\n",
    "df_housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3b1c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте списки количественных и категориальных переменных (не включая целевую переменную)\n",
    "\n",
    "housing_num_feat = ...\n",
    "housing_cat_feat = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522274c9",
   "metadata": {},
   "source": [
    "#### **Что показывает метод [describe](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html)**\n",
    "\n",
    "* **Для числовых (количественных) признаков**\n",
    "\n",
    "    * count — количество не пропущенных значений.\n",
    "\n",
    "    * mean — среднее арифметическое.\n",
    "\n",
    "    * std — стандартное отклонение.\n",
    "\n",
    "    * min — минимальное значение.\n",
    "\n",
    "    * 25% — первый квартиль (25-й процентиль).\n",
    "\n",
    "    * 50% — медиана (50-й процентиль).\n",
    "\n",
    "    * 75% — третий квартиль (75-й процентиль).\n",
    "\n",
    "    * max — максимальное значение.\n",
    "\n",
    "* **Для категориальных признаков**\n",
    "\n",
    "    * count — количество не пропущенных значений.\n",
    "\n",
    "    * unique — число уникальных значений.\n",
    "\n",
    "    * top — самое часто встречающееся значение.\n",
    "    \n",
    "    * freq — частота значения top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8f4aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте статистические характеристики количественных признаков\n",
    "\n",
    "df_housing[housing_num_feat].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98288c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте статистические характеристики категориальных признаков\n",
    "\n",
    "df_housing[housing_cat_feat].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделите объясняемый фактор в отдельную переменную\n",
    "\n",
    "X_housing, y_housing = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de00824c",
   "metadata": {},
   "source": [
    "#### **Как использовать [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)**\n",
    "\n",
    "OneHotEncoder в sklearn преобразует категориальные признаки в бинарные (one-hot) столбцы. \n",
    "\n",
    "Параметры:\n",
    "\n",
    "* drop='first' — удаляет первый столбец для каждого признака (для избежания мультиколлинеарности).\n",
    "\n",
    "* sparse=False — возвращает результат в виде массива numpy вместо разреженной матрицы.\n",
    "\n",
    "*Более продвинутые способы использования — в ColumnTransformer и Pipeline, будут рассмотрены в следующих домашних заданиях.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc41b907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Закодируйте категориальные признаки числами 0 и 1 с помощью OneHotEncoder\n",
    "\n",
    "housing_encoder = OneHotEncoder(sparse_output=False, drop='first').set_output(transform='pandas')\n",
    "\n",
    "X_housing_encoded = ...\n",
    "X_housing = X_housing.join(X_housing_encoded)\n",
    "X_housing = X_housing.drop(columns=...) # Удаляем исходные столбцы после One-Hot кодирования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff8f410",
   "metadata": {},
   "source": [
    "#### **Как использовать [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)**\n",
    "\n",
    "Функция train_test_split позволяет разделить данные на две выборки: обучающую и тестовую.\n",
    "\n",
    "Параметры:\n",
    "\n",
    "* test_size — определяет долю данных, которая пойдет в тестовую выборку.\n",
    "\n",
    "* **random_state** — фиксирует случайное разделение для воспроизводимости результатов.\n",
    "\n",
    "* shuffle (по умолчанию True) — перемешивает данные перед разделением. Если False, данные делятся последовательно.\n",
    "\n",
    "* stratify (по умолчанию None) — обеспечивает стратификацию (передаётся массив меток).\n",
    "\n",
    "**Стратификация** — это способ разделения данных так, чтобы в обучающей и тестовой выборках сохранялось примерно такое же соотношение классов, как в исходных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340db7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# С помощью train_test_split разделите датасет на обучающую (60%) и тестовую (40%) выборки с перемешиванием, без стратификации\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "X_housing_train, X_housing_test, y_housing_train, y_housing_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535ec7f8",
   "metadata": {},
   "source": [
    "#### **Как использовать [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) с обучающей и тестовой выборками для масштабирования количественных признаков**\n",
    "\n",
    "**Основные принципы:**\n",
    "\n",
    "* Обучайте (fit) скейлер только на обучающих данных.\n",
    "\n",
    "* Применяйте преобразование (transform) к обучающим и тестовым данным.\n",
    "\n",
    "* Не обучайте scaler на полной выборке (до разделения), это приведет к [\"утечке информации\" (data leakage)](https://scikit-learn.org/stable/common_pitfalls.html#data-leakage).\n",
    "\n",
    "* [Используйте одинаковое преобразование для train и test](https://scikit-learn.org/stable/common_pitfalls.html#inconsistent-preprocessing).\n",
    "\n",
    "* В рамках домашних заданий применяйте скейлер **только на количественных признаках**.\n",
    "\n",
    "*Более продвинутые способы использования — в ColumnTransformer и Pipeline, будут рассмотрены в следующих домашних заданиях.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ef0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабируйте количественные признаки с помощью StandardScaler\n",
    "#   train -> fit_transform\n",
    "#   test -> transform\n",
    "\n",
    "housing_scaler = StandardScaler().set_output(transform='pandas')\n",
    "\n",
    "X_housing_train_scaled = X_housing_train.copy()\n",
    "X_housing_train_scaled[housing_num_feat] = ... # fit_transform\n",
    "\n",
    "X_housing_test_scaled = X_housing_test.copy()\n",
    "X_housing_test_scaled[housing_num_feat] = ... # transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcda20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте статистические характеристики признаков в обучающей выборке (describe)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ea9299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте статистические характеристики признаков в тестовой выборке (describe)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ff9ae",
   "metadata": {},
   "source": [
    "### **Скорректированный коэффициент детерминации ($Adj.\\;R^2$)**\n",
    "\n",
    "**Скорректированный коэффициент детерминации** ($Adj.\\;R^2$) — это модификация $R^2$, которая учитывает количество факторов в модели и штрафует за добавление незначимых переменных. $Adj.\\;R^2$ рассчитывается по формуле:\n",
    "\n",
    "$$Adj.\\;R^2=1−\\frac{(1-R^2)(n-1)}{n-k-1}$$\n",
    "\n",
    "где $n$ — число наблюдений, $k$ — число факторов в модели.\n",
    "\n",
    "Если при добавлении новых переменных $R^2$ растет (не уменьшается), то $Adj.\\;R^2$ может уменьшиться, если новый фактор не улучшает объясняющую способность модели.\n",
    "\n",
    "При сравнении двух моделей с одинаковым числом признаков можно использовать как $R^2$, так и $Adj.\\;R^2$. Если число признаков у двух моделей отличается, то следует использовать $Adj.\\;R^2$, поскольку $R^2$ не учитывает количество признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14453b8",
   "metadata": {},
   "source": [
    "### ***Задание 4***\n",
    "\n",
    "**ВНИМАНИЕ:** Для решения этого задания используйте:\n",
    "\n",
    "* Обучающую выборку **после масштабирования** из задания 3: `X_housing_train_scaled`.\n",
    "\n",
    "На выборке `X_housing_train_scaled` обучите модель линейной регрессии statsmodels `reg_housing`, и с помощью анализа summary модели `reg_housing` (или с помощью t-теста) определите незначимые **количественные** факторы на уровне значимости 5%.\n",
    "\n",
    "*Использовать t-тест для проверки значимости **категориальной** переменной с $k > 2$ уровней нельзя. Категориальная переменная с $k > 2$ уровнями требует проверки влияния всех уровней одновременно (например, с помощью F-теста), а не попарно. В то же время **категориальные бинарные** ($k = 2$) переменные могут быть проверены на значимость с помощью t-теста.*\n",
    "\n",
    "Далее убедимся, что при добавлении новых незначимых признаков в линейную регрессию:\n",
    "\n",
    "* Коэффициент детерминации $R^2$ растет (не уменьшается).\n",
    "\n",
    "* Скорректированный коэффициент детерминации $Adj.\\;R^2$ уменьшается (не увеличивается).\n",
    "\n",
    "Добавьте в выборку `X_housing_train_scaled` 10 случайных независимых факторов и сравните, насколько изменились $R^2$ и $Adj.\\;R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fea0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите регрессию reg_housing на обучающей выборке\n",
    "# Перед обучением регрессии statsmodels необходимо добавить константу с помощью метода add_constant\n",
    "\n",
    "X_housing_train_scaled_const = ...\n",
    "reg_housing = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf71f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определите незначимые количественные признаки на уровне значимости 5%\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ee81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сгенерируйте случайные факторы и добавьте их в обучающую выборку\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "rng = np.random.RandomState(RANDOM_STATE)\n",
    "\n",
    "noise = pd.DataFrame(\n",
    "        rng.normal(0, 1, size=(X_housing_train_scaled.shape[0], 10)),\n",
    "        index=X_housing_train_scaled.index\n",
    ")\n",
    "\n",
    "X_housing_train_scaled_noise = X_housing_train_scaled.join(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c65693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите регрессию reg_housing на обучающей выборке со случайными факторами\n",
    "# Перед обучением регрессии statsmodels необходимо добавить константу с помощью метода add_constant\n",
    "\n",
    "X_housing_train_scaled_noise_const = ...\n",
    "reg_housing_noise = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc3d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравните, насколько изменились R² и Adj. R² после добавления случайных факторов\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a677859",
   "metadata": {},
   "source": [
    "### ***Задание 5***\n",
    "\n",
    "**ВНИМАНИЕ:** Для решения этого задания используйте:\n",
    "\n",
    "* Обучающую выборку **после масштабирования** из задания 3: `X_housing_train_scaled`, `y_housing_train`.\n",
    "\n",
    "* Тестовую выборку **после масштабирования** из задания 3: `X_housing_test_scaled`, `y_housing_test`.\n",
    "\n",
    "Обучите модель линейной регрессии sklearn с L2-регуляризацией (Ridge) `ridge_housing` с оптимальными гиперпараметрами, подобрав их с помощью GridSearchCV.\n",
    "\n",
    "Используя абсолютные коэффициенты (по модулю) обученной модели `ridge_housing` определите наиболее влиятельный **количественный** признак.\n",
    "\n",
    "Обучите вторую Ridge модель `ridge_housing_area` с оптимальными гиперпараметрами (оптимальные гиперпараметры подберите заново, с помощью GridSearchCV) только на одном параметре — площади (area).\n",
    "\n",
    "Сравните $Adj.\\;R^2$ обученных моделей, используя функцию r2_adj_score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b202de",
   "metadata": {},
   "source": [
    "#### **Как использовать [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) для подбора оптимальных параметров модели**\n",
    "\n",
    "GridSearchCV выполняет перебор всех возможных комбинаций параметров из заданной сетки с кросс-валидацией и обучает модель для каждой такой комбинации. По результатам перебора GridSearchCV выбирает модель, которая оказалась наилучшей с точки зрения заданной метрики обучения (по умолчанию для линейной регрессии — Negative Root Mean Squared Error).\n",
    "\n",
    "**ВНИМАНИЕ:** Оптимальными гиперпараметрами обучения будем считать те, которые привели к обучению наилучшей модели при переборе с помощью GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228974d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подберите оптимальные гиперпараметры обучения ridge_housing с помощью GridSearchCV на всех факторах\n",
    "\n",
    "# Определяем сетку гиперпараметров обучения и количество фолдов\n",
    "params = {\n",
    "    'alpha': [0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0], \n",
    "    'solver': ['saga', 'svd', 'lsqr']\n",
    "}\n",
    "cv = 5\n",
    "\n",
    "# Создаем объект GridSearchCV с указанием модели, сетки параметров и количеством фолдов (5)\n",
    "cv_ridge_housing = GridSearchCV(\n",
    "    estimator=Ridge(random_state=RANDOM_STATE),\n",
    "    param_grid=params,\n",
    "    cv=cv\n",
    ")\n",
    "\n",
    "# Запускаем перебор гиперпараметров и обучение моделей\n",
    "cv_ridge_housing.fit(...)\n",
    "\n",
    "# Посчитаем метрику обучения и оптимальные гиперпараметры лучшей модели\n",
    "print(f'Best score is {cv_ridge_housing.best_score_}, best parameters are {cv_ridge_housing.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba52ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите ridge_housing с оптимальными параметрами на всех факторах\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "ridge_housing = Ridge(**cv_ridge_housing.best_params_, random_state=RANDOM_STATE).fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce46b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используя коэффициенты ridge_housing, определите наиболее влиятельный количественный признак\n",
    "\n",
    "housing_coefs = pd.DataFrame(\n",
    "    {'coef': ...},\n",
    "    index=ridge_housing.feature_names_in_\n",
    ")\n",
    "housing_coefs['significance'] = ....abs()\n",
    "housing_coefs.sort_values(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3488953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте Adj. R² для ridge_housing на тестовой выборке\n",
    "\n",
    "k = len(ridge_housing.feature_names_in_) # Количество факторов\n",
    "print(r2_adj_score(...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fbb524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите ridge_housing_area с оптимальными гиперпараметрами только на одном параметре — площади (area)\n",
    "# Оптимальные гиперпараметры подберите заново, с помощью GridSearchCV\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "params = {\n",
    "    'alpha': [0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0], \n",
    "    'solver': ['saga', 'svd', 'lsqr']\n",
    "}\n",
    "cv = 5\n",
    "\n",
    "cv_ridge_housing_area = ...\n",
    "\n",
    "ridge_housing_area = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте Adj. R² для ridge_housing_area на тестовой выборке\n",
    "\n",
    "k = len(ridge_housing_area.feature_names_in_) # Количество факторов\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c95248c",
   "metadata": {},
   "source": [
    "### ***Задание 6***\n",
    "\n",
    "**ВНИМАНИЕ:** Для решения этого задания используйте:\n",
    "\n",
    "* Обучающую выборку **до и после масштабирования** из задания 3: `X_housing_train`, `X_housing_train_scaled`.\n",
    "\n",
    "* Обученную модель `ridge_housing` из задания 5.\n",
    "\n",
    "Используя `ridge_housing`, определите, как изменится стоимость дома при увеличении количества этажей (stories) на два при прочих равных условиях. Для этого необходимо:\n",
    "\n",
    "1. **Теоретически** рассчитать изменение на основе коэффициента регрессии.\n",
    "\n",
    "2. **Эмпирически** проверить результат, искусственно увеличив количество этажей в **обучающей** выборке, предсказав новую стоимость и рассчитав изменение.\n",
    "\n",
    "**ВНИМАНИЕ:** При теоретическом расчёте изменения **учитывайте масштабирование** количественных признаков. Подсказка: подумайте, как можно использовать scaler.var_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89283bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовьте выборку с увеличенным количеством этажей\n",
    "\n",
    "X_housing_plus2_train = ...\n",
    "X_housing_plus2_train_scaled = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b40094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теоретически рассчитайте изменение на основе коэффициента регрессии\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a471bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эмпирически проверьте результат, предсказав новую стоимость и рассчитав изменение\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b366856-d06a-4c7d-b585-fcfd8854eea6",
   "metadata": {
    "id": "6b366856-d06a-4c7d-b585-fcfd8854eea6",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ***Задание 7***\n",
    "\n",
    "**ВНИМАНИЕ:** Для решения этого задания используйте:\n",
    "\n",
    "* Обучающую выборку **до и после масштабирования** из задания 3: `X_housing_train`, `X_housing_train_scaled`.\n",
    "\n",
    "* Тестовую выборку **до и после масштабирования** из задания 3: `X_housing_test`, `X_housing_test_scaled`, `y_housing_test`.\n",
    "\n",
    "* Обученную модель `ridge_housing` из задания 3.\n",
    "\n",
    "Проверим предположение о том, что ухудшение репрезентативности выборки влияет на качество модели. Для этого рассмотрим три выборки:\n",
    "\n",
    "1. **Обучающая** — полная обучающая выборка, которая использовалась ранее: `X_housing_train`, `X_housing_train_scaled`.\n",
    "\n",
    "2. **Ограниченная обучающая** — обучающая выборка, включающая в себя только данные о домах, в которых площадь не более 3200 (area <= 3200): `X_housing_limited_train`, `X_housing_limited_train_scaled`.\n",
    "\n",
    "3. **Тестовая** — полная тестовая выборка, которая использовалась ранее: `X_housing_test`, `X_housing_test_scaled`.\n",
    "\n",
    "Подготовьте ограниченную обучающую выборку `X_housing_limited_train_scaled` (с масштабированием) и обучите на ней модель Ridge `ridge_housing_limited`, подобрав оптимальные гиперпараметры обучения с помощью GridSearchCV.\n",
    "\n",
    "Сравните $R^2$ для моделей `ridge_housing` и `ridge_housing_limited` на тестовой выборке. Тестовую выборку необходимо правильно масштабировать (см. ниже).\n",
    "\n",
    "**ВНИМАНИЕ:** Для масштабирования ограниченной обучающей выборки используйте новый StandardScaler (`housing_limited_scaler`). Учтите, что тестовую выборку необходимо масштабировать тем же скейлером, что использовался при обучении. Это означает, что при сравнении двух моделей, обученных на выборках с разными скейлерами, необходимо использовать тестовые выборки, преобразованные соответствующими скейлерами:\n",
    "\n",
    "* `ridge_housing` -> `X_housing_test_scaled` (`housing_scaler`).\n",
    "\n",
    "* `ridge_housing_limited` -> `X_housing_limited_test_scaled` (`housing_limited_scaler`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67346e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовьте ограниченную обучающую выборку из исходной (без масштабирования)\n",
    "\n",
    "X_housing_limited_train = X_housing_train[X_housing_train['area'] <= 3200]\n",
    "y_housing_limited_train = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовьте ограниченную обучающую выборку с масштабированием\n",
    "# ВНИМАНИЕ: Используйте новый StandardScaler (housing_limited_scaler)\n",
    "\n",
    "housing_limited_scaler = StandardScaler().set_output(transform='pandas')\n",
    "\n",
    "X_housing_limited_train_scaled[housing_num_feat] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc127f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовьте тестовую выборку с масштабированием (housing_limited_scaler)\n",
    "\n",
    "X_housing_limited_test_scaled[housing_num_feat] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf293dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите ridge_housing_limited на ограниченной обучающей выборке\n",
    "# Оптимальные гиперпараметры обучения подберите с помощью GridSearchCV\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "params = {\n",
    "    'alpha': [0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0], \n",
    "    'solver': ['saga', 'svd', 'lsqr']\n",
    "}\n",
    "cv = 5\n",
    "\n",
    "cv_ridge_housing_limited = ...\n",
    "ridge_housing_limited = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f74dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравните R² для моделей ridge_housing и ridge_housing_limited на тестовых выборках\n",
    "# Используйте тестовые выборки, преобразованные теми же скейлерами, что и обучающая выборка\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bedb31",
   "metadata": {},
   "source": [
    "### **Мультиколлинеарность и VIF**\n",
    "\n",
    "Еще одно из ключевых допущений линейной регрессии — отсутствие мультиколлинеарности между переменными. \n",
    "\n",
    "**Мультиколлинеарность** — это явление, при котором две или более независимые переменные в модели линейной регрессии сильно коррелируют друг с другом. Проще говоря, если изменение одной переменной тесно связано с изменением другой, то они являются мультиколлинеарными.\n",
    "\n",
    "**Последствия мультиколлинеарности:**\n",
    "\n",
    "* Оценки коэффициентов регрессии становятся очень чувствительными к небольшим изменениям в данных.\n",
    "\n",
    "* Усложняется оценка индивидуального влияния каждого фактора на зависимую переменную, так как их эффекты смешиваются.\n",
    "\n",
    "**Методы обнаружения мультиколлинеарности:**\n",
    "\n",
    "* Проверка парных корреляций. Если есть очень высокие значения (например, больше 0.8), это может указывать на наличие мультиколлинеарности.\n",
    "\n",
    "* Variance Inflation Factor (VIF). VIF оценивает, насколько дисперсия коэффициента регрессии увеличивается из-за мультиколлинеарности.\n",
    "\n",
    "Для каждого фактора $X_{j}$​ VIF вычисляется по формуле:\n",
    "\n",
    "$$\\mathrm{VIF}_{j}=\\frac{1}{1-R^2_{j}}$$\n",
    "\n",
    "где $R^2_{j}$​ — коэффициент детерминации модели, в которой строится регрессия $X_{j}$​ на все остальные факторы.\n",
    "\n",
    "**Интерпретация VIF:**\n",
    "\n",
    "* VIF = 1 — фактор не коррелирует с остальными.\n",
    "\n",
    "* 1 < VIF < 5 — фактор умеренно (допустимо) коррелирует с остальными.\n",
    "\n",
    "* VIF ≥ 5 — наличие мультиколлинеарности.\n",
    "\n",
    "**Методы устранения мультиколлинеарности:**\n",
    "\n",
    "* Удаление одной из коррелирующих переменных. Если две переменные мультиколлинеарны, можно удалить одну из них, оставив ту, которая более теоретически обоснована или имеет большее значение.\n",
    "\n",
    "* Объединение переменных. Создание новой переменной, которая является комбинацией мультиколлинеарных переменных.\n",
    "\n",
    "* Использование моделей с регуляризацией. Модели Ridge и LASSO разработаны для работы с мультиколлинеарностью путем добавления штрафа, который уменьшает влияние коррелированных переменных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3b1793",
   "metadata": {},
   "source": [
    "### ***Задание 8***\n",
    "\n",
    "**ВНИМАНИЕ:** Для решения этого задания используйте:\n",
    "\n",
    "* Обучающую выборку **после масштабирования** из задания 3: `X_housing_train_scaled`, `y_housing_train`.\n",
    "\n",
    "* Модель линейной регрессии statsmodels из задания 4: `reg_housing`.\n",
    "\n",
    "Добавьте в обучающую выборку новый фактор something, линейно зависящий от фактора stories (обучающая выборка с фактором something — `X_housing_extended_train_scaled`).\n",
    "\n",
    "Постройте корреляционную матрицу для `X_housing_extended_train_scaled` (метод [corr](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html)).\n",
    "\n",
    "Рассчитайте VIF для всех признаков в `X_housing_extended_train_scaled` (функция [variance_inflation_factor](https://www.statsmodels.org/stable/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html)) и определите наличие мультиколлинеарности.\n",
    "\n",
    "Обучите модель линейной регрессии statsmodels (OLS) `reg_housing_extended` на обучающей выборке `X_housing_extended_train_scaled` (после добавления something).\n",
    "\n",
    "Сравните summary моделей `reg_housing` и `reg_housing_extended`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e415cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавьте в обучающую выборку новый фактор something, линейно зависящий от фактора stories\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "rng = np.random.RandomState(RANDOM_STATE)\n",
    "\n",
    "X_housing_extended_train_scaled = X_housing_train_scaled.copy()\n",
    "X_housing_extended_train_scaled['something'] = X_housing_extended_train_scaled['stories'] * 2 + 0.5 + rng.normal(0, 0.5, X_housing_extended_train_scaled.shape[0])\n",
    "\n",
    "# Стандартизируем новый фактор something (масштабируем)\n",
    "X_housing_extended_train_scaled['something'] = StandardScaler().fit_transform(X_housing_extended_train_scaled[['something']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68aadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте корреляционную матрицу для X_housing_extended_train_scaled\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(..., annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b43bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассчитайте VIF в X_housing_extended_train_scaled для всех признаков и определите наличие мультиколлинеарности\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = X_housing_extended_train_scaled.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(...) \n",
    "               for i in range(...)]\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите модель reg_housing_extended\n",
    "\n",
    "X_housing_extended_train_scaled_const = ...\n",
    "reg_housing_extended = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffca4818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравните summary моделей reg_housing и reg_housing_extended\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65743ed1",
   "metadata": {},
   "source": [
    "### **Гетероскедастичность и тест Уайта**\n",
    "\n",
    "**Гетероскедастичность** — это нарушение одной из ключевых предпосылок классической линейной регрессии, которое заключается в том, что дисперсия (разброс) остатков модели не является постоянной для всех наблюдений.\n",
    "\n",
    "**Последствия гетероскедастичности:**\n",
    "\n",
    "* Неэффективность МНК-оценок — оценки, полученные с помощью метода наименьших квадратов (МНК), не являются наиболее точными.\n",
    "\n",
    "* Смещённость и несостоятельность ковариационной матрицы МНК-оценок. Это приводит к тому, что статистические выводы о качестве полученных оценок (t-тесты, F-тест и доверительные интервалы) могут быть неадекватными.\n",
    "\n",
    "**Выявление гетероскедастичности:**\n",
    "\n",
    "* Графики остатков регрессии. В первом приближении наличие гетероскедастичности можно выявить на графиках остатков регрессии по некоторым переменным, по оцененной зависимой переменной или по номеру наблюдения: разброс точек может меняться в зависимости от значения этих переменных. \n",
    "\n",
    "* Статистические тесты Уайта, Голдфелда-Квандта, Бройша-Пагана, Парка, Глейзера, Спирмена. \n",
    "\n",
    "**Тест Уайта** — это один из наиболее часто применяемых статистических тестов для обнаружения гетероскедастичности, преимущество которого заключается в том, что он не требует заранее предполагать, от чего именно зависит дисперсия ошибки. Суть этого теста заключается в проверке, существует ли статистически значимая связь между квадратами остатков исходной модели и факторами, а также их квадратами и попарными произведениями.\n",
    "\n",
    "**Тест Уайта:**\n",
    "\n",
    "1. Оценивается исходная регрессия и вычисляются её остатки ($e$).\n",
    "\n",
    "2. Строится вспомогательная регрессия квадратов остатков ($e^2$) на исходные признаки, их квадраты и попарные произведения.\n",
    "\n",
    "3. Проверяется гипотеза:\n",
    "\n",
    "    * $H_0$: гетероскедастичности нет (гомоскедастичность, дисперсия ошибок постоянна).\n",
    "    \n",
    "    * $H_1$: гетероскедастичность присутствует."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b5399",
   "metadata": {},
   "source": [
    "### ***Задание 9***\n",
    "\n",
    "**ВНИМАНИЕ:** Для решения этого задания используйте:\n",
    "\n",
    "* Обучающую выборку из задания 3: `X_housing_train_scaled`, `y_housing_train`.\n",
    "\n",
    "* Обученную модель statsmodels из задания 4: `reg_housing`.\n",
    "\n",
    "Посчитайте остатки регрессии `reg_housing` и постройте графики их распределения.\n",
    "\n",
    "Проверьте наличие гетероскедастичности в данных модели `reg_housing` с помощью теста Уайта на уровне значимости 5% ([het_white](https://www.statsmodels.org/stable/generated/statsmodels.stats.diagnostic.het_white.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc58a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте остатки регрессии reg_housing\n",
    "\n",
    "reg_housing_res = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9817305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте график распределения остатков регрессии\n",
    "\n",
    "plt.xlabel('Остатки')\n",
    "plt.ylabel('Частота')\n",
    "reg_housing_res.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0470829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте график распределения остатков reg_housing в зависимости от предсказанных значений (fitted values)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.xlabel('Предсказания объясняемого фактора')\n",
    "plt.ylabel('Отстатки')\n",
    "plt.scatter(\n",
    "    x=..., \n",
    "    y=reg_housing_res\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd06f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполните тест Уайта\n",
    "\n",
    "housing_white_test = het_white(...)\n",
    "\n",
    "housing_white_test_result = pd.DataFrame(\n",
    "    np.round(housing_white_test, 6), \n",
    "    index=['Test Statistic', 'Test Statistic p-value', 'F-Statistic', 'F-Test p-value'], \n",
    "    columns=['Value']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1073754",
   "metadata": {},
   "source": [
    "### **Датасет *Diabetes dataset***\n",
    "\n",
    "**Для решения задания 10 рассмотрим датасет [Diabetes dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset).**\n",
    "\n",
    "Этот маленький датасет (442 наблюдения) предназначен для решения задачи регрессии. Его основная цель — предсказать прогрессирование диабета у пациента через год на основе диагностических показателей. \n",
    "\n",
    "Целевая переменная — числовой показатель, отражающий степень прогрессирования диабета.\n",
    "\n",
    "Набор содержит 10 числовых признаков, которые были предварительно стандартизированы: \n",
    "\n",
    "* age — возраст.\n",
    "\n",
    "* sex — пол.\n",
    "\n",
    "* bmi — индекс массы тела (BMI).\n",
    "\n",
    "* bp — среднее артериальное давление.\n",
    "\n",
    "* s1 (tc) — общий холестерин сыворотки крови (Total Serum Cholesterol).\n",
    "\n",
    "* s2 (ldl) — липопротеины низкой плотности (Low-Density Lipoproteins, \"плохой\" холестерин).\n",
    "\n",
    "* s3 (hdl) — липопротеины высокой плотности (High-Density Lipoproteins, \"хороший\" холестерин).\n",
    "\n",
    "* s4 (tch) — общий холестерин / HDL.\n",
    "\n",
    "* s5 (ltg) — логарифм уровня триглицеридов в сыворотке крови (Log of Serum Triglycerides Level).\n",
    "\n",
    "* s6 (glu) — уровень глюкозы в крови."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e62cbcd",
   "metadata": {},
   "source": [
    "### **Методы регуляризации: Ridge, LASSO**\n",
    "\n",
    "При обучении линейных регрессионных моделей часто возникают две проблемы: переобучение (модель слишком хорошо подстраивается под обучающие данные и плохо работает на новых) и мультиколлинеарность (сильная корреляция между факторами). \n",
    "\n",
    "**Регуляризация** — это метод, который позволяет бороться с этими проблемами путем добавления штрафа за сложность модели к ее функции потерь. Суть метода заключается в том, чтобы заставить модель не только минимизировать ошибку предсказания, но и удерживать коэффициенты при факторах небольшими. \n",
    "\n",
    "Рассмотрим два ключевых метода регуляризации: LASSO (L1-регуляризация) и Ridge (L2-регуляризация).\n",
    "\n",
    "**LASSO (Least Absolute Shrinkage and Selection Operator)**\n",
    "\n",
    "Функция потерь LASSO:\n",
    "\n",
    "$$J(\\theta)=\\text{MSE}(\\theta) + \\alpha \\sum_{i=1}^{k}|\\theta_i|$$\n",
    "\n",
    "где $\\text{MSE}(\\theta)$ — среднеквадратичная ошибка, $\\theta_i$ — коэффициент при $i$-том факторе модели, $\\alpha$ (альфа) — гиперпараметр, контролирующий силу штрафа.\n",
    "\n",
    "LASSO-регрессия способна полностью обнулять коэффициенты при наименее важных факторах. Таким образом, LASSO не только уменьшает сложность модели, но и выполняет отбор наиболее важных признаков.\n",
    "\n",
    "Если в данных есть группа сильно скоррелированных факторов, LASSO имеет тенденцию произвольно выбирать один из них, а остальные обнулять.\n",
    "\n",
    "**Ridge-регрессия**\n",
    "\n",
    "Функция потерь Ridge:\n",
    "\n",
    "$$J(\\theta)=\\text{MSE}(\\theta) + \\alpha \\sum_{i=1}^{k}\\theta_i^2$$\n",
    "    \n",
    "Ridge-регрессия уменьшает абсолютные значения коэффициентов, что делает модель более устойчивой, особенно при наличии мультиколлинеарности. Важная особенность L2-штрафа в том, что он лишь уменьшает коэффициенты, стремясь к нулю, но никогда не обнуляет их полностью. Таким образом, в модели остаются все факторы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7577a1-533c-4cdc-a2d7-0846865a9a7b",
   "metadata": {
    "id": "3e7577a1-533c-4cdc-a2d7-0846865a9a7b",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ***Задание 10***\n",
    "\n",
    "Выполните предобработку датасета (см. код задания) и обучите три линейных регрессии sklearn:\n",
    "\n",
    "* `reg_diab` — регрессия без регуляризации (LinearRegression).\n",
    "\n",
    "* `lasso_diab` — регрессия с L1-регуляризацией (LASSO). Оптимальные гиперпараметры обучения подберите с помощью GridSearchCV.\n",
    "\n",
    "* `ridge_diab` — регрессия с L2-регуляризацией (Ridge). Оптимальные гиперпараметры обучения подберите с помощью GridSearchCV.\n",
    "\n",
    "Для каждой из моделей выведите metrics_report на тестовой выборке и определите признаки, которые были исключены из регрессии L1-регуляризацией (LASSO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21553ef0-2da8-4cf8-9b11-0e4aaf164a42",
   "metadata": {
    "id": "21553ef0-2da8-4cf8-9b11-0e4aaf164a42",
    "outputId": "b6a4b499-05d3-4618-d62f-b0fe82756f3f"
   },
   "outputs": [],
   "source": [
    "# Загрузите набор данных с помощью sklearn.datasets и выделите объясняемый фактор в отдельную переменную\n",
    "\n",
    "df_diab = datasets.load_diabetes()\n",
    "X_diab = pd.DataFrame(df_diab.data)\n",
    "X_diab.columns = df_diab.feature_names\n",
    "y_diab = df_diab.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed46e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализуйте значение целевой переменной\n",
    "\n",
    "y_diab = (y_diab - y_diab.min()) / (y_diab.max() - y_diab.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a49190-06a0-4e8a-9811-65e3d7f74c8d",
   "metadata": {
    "id": "84a49190-06a0-4e8a-9811-65e3d7f74c8d"
   },
   "outputs": [],
   "source": [
    "# Разделите датасет на обучающую (75%) и тестовую (25%) выборки (с перемешиванием, без стратификации)\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "X_diab_train, X_diab_test, y_diab_train, y_diab_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51956b1a-23a1-4547-ad89-2b6b42dfc6ec",
   "metadata": {
    "id": "51956b1a-23a1-4547-ad89-2b6b42dfc6ec",
    "outputId": "2545e9a3-4847-44c1-faf6-569e28990a0a"
   },
   "outputs": [],
   "source": [
    "# Обучите линейную регрессию без регуляризации reg_diab и выведите metrics_report на тестовой выборке\n",
    "\n",
    "reg_diab = ...\n",
    "metrics_report(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c95d93-fd09-47bf-a9f9-c1ac638bf607",
   "metadata": {
    "id": "f9c95d93-fd09-47bf-a9f9-c1ac638bf607",
    "outputId": "a6adc6b2-f019-4cd7-baa7-810800d6b132"
   },
   "outputs": [],
   "source": [
    "# Обучите модель lasso_diab (LASSO) и выведите metrics_report на тестовой выборке\n",
    "# Оптимальные гиперпараметры обучения подберите с помощью GridSearchCV\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "params = {'alpha' : [0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "cv = 5\n",
    "\n",
    "cv_lasso_diab = ...\n",
    "lasso_diab = ...\n",
    "\n",
    "metrics_report(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите модель ridge_diab (Ridge) и выведите metrics_report на тестовой выборке\n",
    "# Оптимальные гиперпараметры обучения подберите с помощью GridSearchCV\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "params = {'alpha' : [0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "cv = 5\n",
    "\n",
    "cv_ridge_diab = ...\n",
    "ridge_diab = ...\n",
    "\n",
    "metrics_report(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34502d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассмотрите коэффициенты моделей\n",
    "\n",
    "diab_coefs = pd.DataFrame({\n",
    "    'reg_diab coef': ...,\n",
    "    'lasso_diab coef': ...,\n",
    "    'ridge_diab coef': ...\n",
    "}, index=X_diab.columns\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
